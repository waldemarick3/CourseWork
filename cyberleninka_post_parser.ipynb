{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7340c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "48852a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Dict, Tuple, List\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def extract_title(html_string: str) -> Optional[str]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        title_tag = soup.find('i', {'itemprop': 'headline'})\n",
    "        return title_tag.text.strip() if title_tag else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_license(html_string: str) -> Optional[str]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        license_element = soup.find('div', {'class': 'statitem label-cc'})\n",
    "        return license_element['title'] if license_element else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_views(html_string: str) -> Optional[int]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        views_div = soup.find('div', {'class': 'statitem views'})\n",
    "        if views_div:\n",
    "            views = views_div.get_text().replace('\\n', '').strip()\n",
    "            return int(views)\n",
    "        else:\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_downloads(html_string: str) -> Optional[int]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        downloads_div = soup.find('div', {'class': 'statitem downloads'})\n",
    "        if downloads_div:\n",
    "            downloads_str = downloads_div.text.strip()\n",
    "            return int(downloads_str)\n",
    "        else:\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_likes(html_string: str) -> Optional[Dict[str, Union[str, int]]]:\n",
    "    try:\n",
    "        pattern = r'\"likes\":\"(\\d+)\",\"dislikes\":\"(\\d+)\",\"user\":(\\d+)'\n",
    "        match = re.search(pattern, html_string)\n",
    "        if match:\n",
    "            return {\"likes\": int(match.group(1)), \"dislikes\": int(match.group(2))}\n",
    "        else:\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_author_info(html_string: str) -> Optional[Dict[str, Union[int, str]]]:\n",
    "    try:\n",
    "        pattern = r'\"id\":\\s*(\\d+),\\s*\"name\":\\s*\"([^\"]+)\"'\n",
    "        match = re.search(pattern, html_string)\n",
    "        if match:\n",
    "            author_id = int(match.group(1))\n",
    "            author_name = match.group(2)\n",
    "            return {\"id\": author_id, \"name\": author_name}\n",
    "        else:\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_keywords(html_string: str) -> Tuple[str, ...]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        m = soup.find('i', {'itemprop': 'keywords'})\n",
    "        if m:\n",
    "            keywords_str = m.text\n",
    "            keywords = re.findall(r'<span[^>]*>(.*?)</span>', keywords_str, re.DOTALL)\n",
    "            keywords = [k.strip() for k in keywords]\n",
    "            return tuple(keywords)\n",
    "        else:\n",
    "            return ()\n",
    "    except Exception:\n",
    "        return ()\n",
    "\n",
    "\n",
    "def extract_similar_articles(html_string: str) -> List[Dict[str, str]]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        articles = []\n",
    "        for article in soup.find_all('li'):\n",
    "            link = article.find('a')['href']\n",
    "            title = article.find('div', {'class': 'title'}).text\n",
    "            articles.append({'title': title, 'link': 'https://cyberleninka.ru' + link})\n",
    "        return articles\n",
    "    except Exception:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e5241443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_cyberleninka_post(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status() \n",
    "    except requests.exceptions.RequestException:\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    post_dict = {\n",
    "    'license': None,\n",
    "    'views': None,\n",
    "    'downloads': None,\n",
    "    'title': None,\n",
    "    'title_href': str(url),\n",
    "    'votes': None,\n",
    "    'author': None,\n",
    "    'keywords': None,\n",
    "    'annotation': None,\n",
    "    'time': None,\n",
    "    'similar': None\n",
    "}\n",
    "\n",
    "    author_elem = soup.find('div', {'class': 'infoblock'})\n",
    "    post_dict['license'] = extract_license(str(author_elem))\n",
    "    post_dict['views'] = extract_views(str(author_elem))\n",
    "    post_dict['downloads'] = extract_downloads(str(author_elem))\n",
    "\n",
    "    title_elem = soup.find('h1')\n",
    "    post_dict['title'] = extract_title(str(title_elem))\n",
    "\n",
    "    keywords_elem = soup.find('div', {'class': 'keywords'})\n",
    "    post_dict['keywords'] = extract_keywords(str(keywords_elem))\n",
    "\n",
    "    annotation_elem = soup.find('p', {'itemprop': 'description'})\n",
    "    if annotation_elem:\n",
    "        post_dict['annotation'] = annotation_elem.text.strip()\n",
    "\n",
    "    time_elem = soup.find('time', {'itemprop': 'datePublished'})\n",
    "    if time_elem:\n",
    "        post_dict['time'] = time_elem.text.strip()\n",
    "\n",
    "    similar_elem = soup.find('ul', {'class': 'list'})\n",
    "    post_dict['similar'] = extract_similar_articles(str(similar_elem))\n",
    "\n",
    "    return post_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "131ddf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'license': 'Лицензия Creative Commons', 'views': 460126, 'downloads': 1504, 'title': 'Бальзаковский возраст', 'title_href': 'https://cyberleninka.ru/article/n/balzakovskiy-vozrast', 'votes': None, 'author': None, 'keywords': (), 'annotation': '«Бальзаковский возраст» русская идиома, не существующая в других языках. Это выражение появилось в 1880-е годы, а его самые ранние формы почти на полвека раньше. Вопреки нередко бытующим представлениям, «бальзаковский возраст» с самого начала понимался так же, как он понимается и теперь.', 'time': '2017', 'similar': [{'title': 'Натурщица и шедевр (Бальзак и его продолжатели)', 'link': 'https://cyberleninka.ru/article/n/naturschitsa-i-shedevr-balzak-i-ego-prodolzhateli'}, {'title': 'Образ Вотрена в «Человеческой комедии» Бальзака', 'link': 'https://cyberleninka.ru/article/n/obraz-votrena-v-chelovecheskoy-komedii-balzaka'}, {'title': '«Блаженные слова» (пространство одной строки Осипа Мандельштама)', 'link': 'https://cyberleninka.ru/article/n/blazhennye-slova-prostranstvo-odnoy-stroki-osipa-mandelshtama'}, {'title': 'Концепция тезаурусных сфер', 'link': 'https://cyberleninka.ru/article/n/kontseptsiya-tezaurusnyh-sfer'}, {'title': 'Символика романа Бальзака \"Серафита\"', 'link': 'https://cyberleninka.ru/article/n/simvolika-romana-balzaka-serafita'}]}\n"
     ]
    }
   ],
   "source": [
    "print(parse_cyberleninka_post('https://cyberleninka.ru/article/n/balzakovskiy-vozrast'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
