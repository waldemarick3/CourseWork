{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7340c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "48852a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import datetime\n",
    "from typing import Optional, Tuple, Dict, Union\n",
    "\n",
    "def extract_username(input_str: str) -> Optional[str]:\n",
    "    try:\n",
    "        pattern = re.compile(r'/users/(.*?)/\">')\n",
    "        match = pattern.search(input_str)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_timestamp(input_str: str) -> Optional[int]:\n",
    "    try:\n",
    "        pattern = re.compile(r'<time datetime=\"(.*?)\" title=\".*?\">')\n",
    "        match = pattern.search(input_str)\n",
    "        if match:\n",
    "            timestamp_str = match.group(1)\n",
    "            timestamp = datetime.datetime.strptime(timestamp_str, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "            return int((timestamp - datetime.datetime(1970, 1, 1)).total_seconds())\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_title(input_str: str) -> Optional[str]:\n",
    "    try:\n",
    "        pattern = re.compile(r'<span>(.*?)</span>')\n",
    "        match = pattern.search(input_str)\n",
    "        if match:\n",
    "            title_str = match.group(1)\n",
    "            return title_str.strip()\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_views(input_str: str) -> Optional[int]:\n",
    "    try:\n",
    "        pattern = re.compile(r'([\\d\\.]+)([KkMmBbTt]?)')\n",
    "        match = pattern.search(input_str)\n",
    "        if match:\n",
    "            num_str = match.group(1)\n",
    "            suffix = match.group(2).lower()\n",
    "            num = float(num_str)\n",
    "            if suffix == 'k':\n",
    "                num *= 1000\n",
    "            elif suffix == 'm':\n",
    "                num *= 1000000\n",
    "            elif suffix == 'b':\n",
    "                num *= 1000000000\n",
    "            elif suffix == 't':\n",
    "                num *= 1000000000000\n",
    "            return int(num)\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_hub_names(html: str) -> Tuple[str, ...]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        hubs = soup.find('div', {'class': 'tm-article-snippet__hubs'})\n",
    "        hub_names = [hub.text.strip() for hub in hubs.find_all('span', {'class': 'tm-article-snippet__hubs-item'})]\n",
    "        return tuple(hub_names)\n",
    "    except:\n",
    "        return tuple()\n",
    "\n",
    "def parse_votes(s: str) -> Optional[Dict[str, int]]:\n",
    "    try:\n",
    "        pattern = re.compile(r'↑(\\d+).*↓(\\d+)')\n",
    "        match = pattern.search(s)\n",
    "        if match:\n",
    "            return {'upvotes': int(match.group(1)), 'downvotes': int(match.group(2))}\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_bookmarks_count(text: str) -> Optional[int]:\n",
    "    try:\n",
    "        pattern = r'<span\\s+class=\"bookmarks-button__counter\".*?>\\s*(\\d+)\\s*</span>'\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_href(string: str) -> Optional[str]:\n",
    "    try:\n",
    "        pattern = r'href=\"(.+?)\"'\n",
    "        href = re.search(pattern, string).group(1)\n",
    "        return 'https://habr.com'+href\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_comments_count(text: str) -> Optional[int]:\n",
    "    try:\n",
    "        count_str = re.search(r'\\d+', text).group()\n",
    "        return int(count_str)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_tags(input_string):\n",
    "    try:\n",
    "        tag_links = re.findall('<a class=\"tm-tags-list__link\" href=\".+?\">(.+?)</a>', input_string)\n",
    "        return tag_links\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "def extract_text(html_string):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        tags = ['p']\n",
    "        text = ''\n",
    "        for tag in tags:\n",
    "            elements = soup.find_all(tag)\n",
    "            for element in elements:\n",
    "                text += element.get_text() + '.'\n",
    "        return text\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_urls(html_string):\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        urls = []\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            url = link['href']\n",
    "            if re.match(r'^https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', url):\n",
    "                urls.append(url)\n",
    "        return urls\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_first_n_sentences(text, n=10):\n",
    "    try:\n",
    "        sentences = text.split('.')\n",
    "        non_empty_sentences = [s.strip() for s in sentences if s.strip()]\n",
    "        return non_empty_sentences[:n]\n",
    "    except:\n",
    "        return [] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5241443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_hubr_posts(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    post_dict = {}\n",
    "\n",
    "    author_elem = soup.find('a', {'class': 'tm-user-info__username'})\n",
    "    post_dict['author'] = extract_username(str(author_elem))\n",
    "    post_dict['author_href'] = extract_href(str(author_elem))\n",
    "\n",
    "    date_elem = soup.find('span', {'class': 'tm-article-datetime-published'})\n",
    "    post_dict['date'] =extract_timestamp(str(date_elem))\n",
    "\n",
    "    title_elem = soup.find('h1', {'class': 'tm-article-snippet__title tm-article-snippet__title_h1'})\n",
    "    post_dict['title'] = extract_title(str(title_elem))\n",
    "    post_dict['title_href'] = str(url)\n",
    "\n",
    "    views_elem = soup.find('span', {'class': 'tm-icon-counter__value'})\n",
    "    post_dict['views'] = extract_views(str(views_elem))\n",
    "\n",
    "    hubs_elem = soup.find('div', {'class': 'tm-article-snippet__hubs'})\n",
    "    post_dict['hubs'] = extract_hub_names(str(hubs_elem))\n",
    "\n",
    "    votes_elem = soup.find('div', {'class': 'tm-votes-meter'})\n",
    "    post_dict['votes'] = parse_votes(str(votes_elem))\n",
    "\n",
    "    bookmarks_elem = soup.find('span', {'class': 'bookmarks-button__counter'})\n",
    "    post_dict['bookmarks'] = extract_bookmarks_count(str(bookmarks_elem))\n",
    "\n",
    "    comments_elem = soup.find('span', {'class': 'tm-article-comments-counter-link__value'})\n",
    "    post_dict['comments'] = extract_comments_count(str(comments_elem))\n",
    " \n",
    "    tags_elem = soup.find('div', {'class': 'tm-article-presenter__meta'})\n",
    "    post_dict['tags'] = extract_tags(str(tags_elem))\n",
    "    \n",
    "    text_elem = soup.find('div', {'id': 'post-content-body'})\n",
    "    post_dict['hrefs'] = extract_urls(str(text_elem))\n",
    "    post_dict['text'] = get_first_n_sentences(extract_text(str(text_elem)))\n",
    "    \n",
    "    return post_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "131ddf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'dimitryabramov', 'author_href': 'https://habr.com/ru/users/dimitryabramov/', 'date': 1678135430, 'title': 'Тайны мозга. Анализируем данные MRI с помощью FreeSurfer и Python', 'title_href': 'https://habr.com/ru/post/720848/', 'views': 54, 'hubs': ('Python *', 'Мозг', 'Будущее здесь', 'Научно-популярное', 'Визуализация данных *'), 'votes': None, 'bookmarks': 0, 'comments': 0, 'tags': ['neuroscience', 'нейробиология', 'мозг', 'визуализация данных', 'будущее', 'python', 'исследование'], 'hrefs': ['https://surfer.nmr.mgh.harvard.edu/', 'https://surfer.nmr.mgh.harvard.edu/fswiki/DownloadAndInstall', 'https://openneuro.org/', 'https://www.humanconnectome.org/', 'https://brainminds.jp/en/', 'https://www.cancerimagingarchive.net/'], 'text': ['Визуализация мозга это революционное направление в неврологии, оно позволяет исследователям получать беспрецедентное представление о структуре и функциях человеческого мозга', 'Одной из областей, где визуализация показала особые перспективы, является выявление паттернов мозговой активности, связанных с различными предрасположенностями, такими как черты личности, когнитивные способности и психические расстройства', 'В этой статье мы рассмотрим, как эту технологию можно использовать для выявления предрасположенностей человека, и какие открытия были сделаны в этой области, увидим как, используя данные MRI получить сведения о базовых структурах мозга на примере его коры', 'Прежде чем мы углубимся в детали, давайте начнем с краткого обзора', 'Существует несколько методов, которые можно использовать для визуализации головного мозга, это магнитно-резонансная томография (MRI), функциональная магнитно-резонансная томография (fMRI), позитронно-эмиссионная томография (PET) и электроэнцефалография (EEG)', 'MRI дает подробные изображения структуры мозга, а fMRI, PET и EEG используются для измерения мозговой активности', 'Теперь рассмотрим, каким путем можно использовать данные о мозге для вывления предрасположенностей человека', 'Один из подходов заключается в изучении мозговой активности людей, проявляющих определенную склонность, и сравнении ее с мозговой активностью тех, у кого такой склонности нет', 'Например, исследователи могут сравнить мозговую активность людей с высокими баллами по такой черте личности, как экстраверсия, с мозговой активностью тех, у кого низкие баллы', 'Выявив различия в активности мозга между двумя группами, исследователи могут получить представление о нейронных механизмах, лежащих в основе склонности данного типа']}\n"
     ]
    }
   ],
   "source": [
    "print(parse_hubr_posts('https://habr.com/ru/post/720848/'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
