{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7340c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "48852a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Dict, Tuple, List\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def extract_title(html_string: str) -> Optional[str]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        title_tag = soup.find('i', {'itemprop': 'headline'})\n",
    "        return title_tag.text.strip() if title_tag else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def extract_labels(html_string: str) -> Tuple[str]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        label_div = soup.find('div', {'class': 'labels'})\n",
    "        labels = label_div.find_all('div', {'class': 'label'})\n",
    "        label_names = [label.text.strip() for label in labels if label.text.strip() != '' and label.get('itemprop') is None]\n",
    "        return tuple(label_names[1:])\n",
    "    except Exception:\n",
    "        return ()\n",
    "\n",
    "def extract_views(html_string: str) -> Optional[int]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        views_div = soup.find('div', {'class': 'statitem views'})\n",
    "        if views_div:\n",
    "            views = views_div.get_text().replace('\\n', '').strip()\n",
    "            return int(views)\n",
    "        else:\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_downloads(html_string: str) -> Optional[int]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        downloads_div = soup.find('div', {'class': 'statitem downloads'})\n",
    "        if downloads_div:\n",
    "            downloads_str = downloads_div.text.strip()\n",
    "            return int(downloads_str)\n",
    "        else:\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_likes(html_string: str) -> Optional[Dict[str, Union[str, int]]]:\n",
    "    try:\n",
    "        pattern = r'\"likes\":\"(\\d+)\",\"dislikes\":\"(\\d+)\",\"user\":(\\d+)'\n",
    "        match = re.search(pattern, html_string)\n",
    "        if match:\n",
    "            return {\"likes\": int(match.group(1)), \"dislikes\": int(match.group(2))}\n",
    "        else:\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_author_info(html_string: str) -> Optional[List[Dict[str, Union[int, str]]]]:\n",
    "    try:\n",
    "        pattern = r'\"id\":\\s*(\\d+),\\s*\"name\":\\s*\"([^\"]+)\"'\n",
    "        matches = re.findall(pattern, html_string)\n",
    "        if matches:\n",
    "            authors = []\n",
    "            for match in matches:\n",
    "                author_id = int(match[0])\n",
    "                author_name = match[1]\n",
    "                if not any(author.get('id') == author_id for author in authors):\n",
    "                    authors.append({\"id\": author_id, \"name\": author_name})\n",
    "            if len(authors) > 0:\n",
    "                return authors\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_keywords(html_string: str) -> Tuple[str, ...]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        m = soup.find('i', {'itemprop': 'keywords'})\n",
    "        if m:\n",
    "            keywords_str = str(m)\n",
    "            keywords = re.findall(r'<span[^>]*>(.*?)</span>', keywords_str, re.DOTALL)\n",
    "            keywords = [re.sub(r'<[^>]*>', '', k).strip() for k in keywords]\n",
    "            return tuple(keywords)\n",
    "        else:\n",
    "            return ()\n",
    "    except Exception:\n",
    "        return ()\n",
    "\n",
    "\n",
    "def extract_similar_articles(html_string: str) -> List[Dict[str, str]]:\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_string, 'html.parser')\n",
    "        articles = []\n",
    "        for article in soup.find_all('li'):\n",
    "            link = article.find('a')['href']\n",
    "            title = article.find('div', {'class': 'title'}).text\n",
    "            articles.append({'title': title, 'link': 'https://cyberleninka.ru' + link})\n",
    "        return articles\n",
    "    except Exception:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e5241443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_cyberleninka_post(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status() \n",
    "    except requests.exceptions.RequestException:\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    post_dict = {\n",
    "    'license': None,\n",
    "    'views': None,\n",
    "    'downloads': None,\n",
    "    'title': None,\n",
    "    'title_href': str(url),\n",
    "    'votes': None,\n",
    "    'author': None,\n",
    "    'keywords': None,\n",
    "    'annotation': None,\n",
    "    'time': None,\n",
    "    'similar': None\n",
    "}\n",
    "\n",
    "    stat_elem = soup.find('div', {'class': 'infoblock'})\n",
    "    post_dict['views'] = extract_views(str(stat_elem))\n",
    "    post_dict['downloads'] = extract_downloads(str(stat_elem))\n",
    "\n",
    "    title_elem = soup.find('h1')\n",
    "    post_dict['title'] = extract_title(str(title_elem))\n",
    "\n",
    "    keywords_elem = soup.find('div', {'class': 'keywords'})\n",
    "    post_dict['keywords'] = extract_keywords(str(keywords_elem))\n",
    "    \n",
    "    post_dict['votes'] = extract_likes(str(soup))\n",
    "\n",
    "    post_dict['author'] = extract_author_info(str(soup))\n",
    "\n",
    "    annotation_elem = soup.find('p', {'itemprop': 'description'})\n",
    "    if annotation_elem:\n",
    "        post_dict['annotation'] = annotation_elem.text.strip()\n",
    "\n",
    "    time_elem = soup.find('time', {'itemprop': 'datePublished'})\n",
    "    if time_elem:\n",
    "        post_dict['time'] = time_elem.text.strip()\n",
    "\n",
    "    similar_elem = soup.find('ul', {'class': 'list'})\n",
    "    post_dict['similar'] = extract_similar_articles(str(similar_elem))\n",
    "\n",
    "    label_elem = soup.find('div', {'class': 'labels'})\n",
    "    post_dict['license'] = extract_labels(str(label_elem))\n",
    "\n",
    "    return post_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "131ddf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'license': ('Scopus', 'ВАК', 'RSCI'), 'views': 97897, 'downloads': 556, 'title': 'Сравнительная оценка эффективности рабепразола и омепразола в терапии гастроэзофагеальной рефлюксной болезни', 'title_href': 'https://cyberleninka.ru/article/n/sravnitelnaya-otsenka-effektivnosti-rabeprazola-i-omeprazola-v-terapii-gastroezofagealnoy-reflyuksnoy-bolezni', 'votes': {'likes': 0, 'dislikes': 0}, 'author': [{'id': 21263225, 'name': 'Гималетдинова Ирина Анатольевна'}, {'id': 21263226, 'name': 'Абсалямова Лэйлэ Равиловна'}, {'id': 21263227, 'name': 'Амиров Наиль Багаувич'}], 'keywords': ('РАБЕПРАЗОЛ', 'ЦИТОХРОМ CYP450', 'ДИСПЕПТИЧЕСКИЕ ЯВЛЕНИЯ', 'ПРИВЕРЖЕННОСТЬ ЛЕЧЕНИЮ', 'ОПРОСНИК GERDG', 'RABEPRAZOLE', 'CYTOCHROME CYP450', 'COMPLIANCE', 'SURVEY GERDG'), 'annotation': 'Гастроэзофагеальная рефлюксная болезнь это состояние, развивающееся, когда рефлюкс содержимого желудка вызывает появление беспокоящих больного симптомов и/или развитие осложнений. Выделение гастроэзофагеальной рефлюксной болезни в отдельную нозологию в конце XX в. обусловлено высокой распространенностью данного заболевания и перманентной тенденцией к росту. Препаратами первого выбора для лечения этого заболевания являются ингибиторы протонной помпы. Цель исследования провести сравнительную оценку эффективности терапии гастроэзофагеальной рефлюксной болезни (неосложненной и эрозивной) препаратами класса ингибиторов протонной помпы: омепразолом, применяемым в дозе 40 мг/сут за 30 мин до завтрака и рабепразолом-CЗ в форме кишечно-растворимых капсул в дозе 20 мг/сут за 30 мин до завтрака (возможно применение независимо от приема пищи) в сочетании с антацидами, прокинетиками, используемыми в стандартных дозировках, с точки зрения купирования симптомов и заживления рефлюкс-эзофагита. Материал и методы. Представлены результаты клинического исследования, в ходе которого наблюдались 2 группы пациентов по 20 человек каждая в возрасте от 25 до 65 лет. Средний возраст пациентов составлял 45 лет. Продолжительность исследования составляла 4 нед (28 дней). Результаты и их обсуждение. Полученные данные свидетельствуют о большей эффективности рабепразола-СЗ для лечения гастроэзофагеальной рефлюксной болезни по сравнению с омепразолом. Он обеспечивает быстрое и стойкое устранение симптоматики, что улучшает приверженность к терапии у 100% пациентов. Заключение. Рабепразол-СЗ в дозе 20 мг/сут при лечении гастроэзофагеальной рефлюксной болезни быстрее уменьшает выраженность изжоги и диспептических явлений по сравнению с омепразолом в дозе 40 мг/сут, особенно на фоне строгого выполнении рекомендаций по изменению образа жизни и привычек, а также быстрее способствует заживлению эрозии и восстановлению нормальной слизистой оболочки пищевода. Установлена хорошая переносимость 4-недельного курса терапии препаратом рабепразол-СЗ.', 'time': '2017', 'similar': [{'title': 'Сравнительный анализ эффективности ингибиторов протонной помпы в лечении эзофагита у пожилых', 'link': 'https://cyberleninka.ru/article/n/sravnitelnyy-analiz-effektivnosti-ingibitorov-protonnoy-pompy-v-lechenii-ezofagita-u-pozhilyh'}, {'title': 'Эффективная кислотосупрессия как основа терапии гастроэзофагеальной рефлюксной болезни', 'link': 'https://cyberleninka.ru/article/n/effektivnaya-kislotosupressiya-kak-osnova-terapii-gastroezofagealnoy-reflyuksnoy-bolezni'}, {'title': 'Омепразол в терапии кислотозависимых заболеваний', 'link': 'https://cyberleninka.ru/article/n/omeprazol-v-terapii-kislotozavisimyh-zabolevaniy'}, {'title': 'Применение ингибиторов протонной помпы в гастроэнтерологии', 'link': 'https://cyberleninka.ru/article/n/primenenie-ingibitorov-protonnoy-pompy-v-gastroenterologii'}, {'title': 'Лечение больных эрозивным эзофагитом современный взгляд на проблему', 'link': 'https://cyberleninka.ru/article/n/lechenie-bolnyh-erozivnym-ezofagitom-sovremennyy-vzglyad-na-problemu'}]}\n"
     ]
    }
   ],
   "source": [
    "url ='https://cyberleninka.ru/article/n/sravnitelnaya-otsenka-effektivnosti-rabeprazola-i-omeprazola-v-terapii-gastroezofagealnoy-reflyuksnoy-bolezni'\n",
    "url2 = 'https://cyberleninka.ru/article/n/balzakovskiy-vozrast'\n",
    "print(parse_cyberleninka_post(url))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
